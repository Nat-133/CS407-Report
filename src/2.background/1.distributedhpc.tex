\section{Distributed High Performance Computing}
High performance on certain parallelizable computing tasks can be achieved by partitioning and distributing the task over multiple machines in a network. This allows for a more scalable approach to high performance; monolithic system supercomputers are more expensive. However, existing sequential code for tasks suited to distribution cannot immediately make use of these benefits, as sequential to parallel code translation alone has found limited success. For many problems the most efficient parallel algorithms are unique to that problem and as such it is hard to use common patterns in translation. As such, for the highest performance, the responsibility falls to the programmer to write parallel, distributed code, including any data or task parallelism and inter-node communication. For scientific experts looking to utilise high performance computing for their applications and simulations these lower level non-abstract concerns  might present challenges. A method particularly useful to scientific simulations and amenable to parallelisation is the use of unstructured meshes.